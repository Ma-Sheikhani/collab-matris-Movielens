{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1v9KKu7I3oNY0fGtMmBZTbvbCVcGF9OgP",
      "authorship_tag": "ABX9TyMTEk5Sl9HAWFxe2mB4VDCW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ma-Sheikhani/collab-matris-Movielens/blob/main/colab_matris%2C_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://files.grouplens.org/datasets/movielens/ml-25m.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doK2fB65c3Fl",
        "outputId": "e1a298bf-0554-4923-f2e0-f2c96c983522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-12 11:45:27--  https://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 261978986 (250M) [application/zip]\n",
            "Saving to: ‘ml-25m.zip’\n",
            "\n",
            "ml-25m.zip          100%[===================>] 249.84M  62.4MB/s    in 4.4s    \n",
            "\n",
            "2023-12-12 11:45:32 (56.8 MB/s) - ‘ml-25m.zip’ saved [261978986/261978986]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install patool\n",
        "import patoolib\n",
        "patoolib.extract_archive('/content/ml-25m.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "QHxWqJAvc79M",
        "outputId": "fcd297fa-90b7-416b-b0d2-eea847670db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patool\n",
            "  Downloading patool-2.0.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.7/93.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-2.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO patool: Extracting /content/ml-25m.zip ...\n",
            "INFO:patool:Extracting /content/ml-25m.zip ...\n",
            "INFO patool: running /usr/bin/7z x -o./Unpack_7tc0hl3l -- /content/ml-25m.zip\n",
            "INFO:patool:running /usr/bin/7z x -o./Unpack_7tc0hl3l -- /content/ml-25m.zip\n",
            "INFO patool:     with input=''\n",
            "INFO:patool:    with input=''\n",
            "INFO patool: ... /content/ml-25m.zip extracted to `ml-25m'.\n",
            "INFO:patool:... /content/ml-25m.zip extracted to `ml-25m'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ml-25m'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "hSnmCm0edezr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = pd.read_csv('/content/ml-25m/ratings.csv')"
      ],
      "metadata": {
        "id": "VIyn67-9eJAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.drop(axis=1 , labels = 'timestamp',inplace = True)\n",
        "ratings = ratings.iloc[:50000,:]\n"
      ],
      "metadata": {
        "id": "GgPdd1A5eyEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTabularDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.labels = data.iloc[:,-1]\n",
        "        self.data = data.iloc[:,:-1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, indx):\n",
        "        data = torch.tensor(self.data.iloc[indx])\n",
        "        label = torch.tensor(self.labels.iloc[indx],dtype=torch.float64)\n",
        "\n",
        "        return data, label"
      ],
      "metadata": {
        "id": "dQzw-1ahnYcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Training , Test = train_test_split(ratings,test_size=0.2)\n",
        "\n",
        "Training_dataset = CustomTabularDataset(Training)\n",
        "Test_dataset = CustomTabularDataset(Test)\n",
        "\n",
        "train_d = DataLoader(Training_dataset, batch_size = 256, drop_last=False, shuffle = True)\n",
        "test_d = DataLoader(Test_dataset, batch_size = 256, drop_last=False, shuffle = True)"
      ],
      "metadata": {
        "id": "UjGbVkCGonUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_params(size):\n",
        "    return torch.nn.Parameter(torch.zeros(*size).normal_(0, 0.01))"
      ],
      "metadata": {
        "id": "JNVdv8Z3h8n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DotProductBias(torch.nn.Module):\n",
        "    def __init__(self, n_users, n_movies, n_factors, movie_code, user_code):\n",
        "        super(DotProductBias, self).__init__()\n",
        "\n",
        "        self.user_factors = create_params([n_users, n_factors])\n",
        "        self.user_bias = create_params([n_users])\n",
        "        self.movie_factors = create_params([n_movies, n_factors])\n",
        "        self.movie_bias = create_params([n_movies])\n",
        "\n",
        "        self.double()\n",
        "\n",
        "\n",
        "        self.movie_code = movie_code\n",
        "        self.user_code = user_code\n",
        "\n",
        "    def forward(self, x):\n",
        "        index_user_list = [int(np.where(self.user_code == np.array(a[0]))[0]) for a in x]\n",
        "        index_movie_list = [int(np.where(self.movie_code == np.array(a[1]))[0]) for a in x]\n",
        "\n",
        "\n",
        "        users = self.user_factors[index_user_list]\n",
        "        movies = self.movie_factors[index_movie_list]\n",
        "\n",
        "\n",
        "        res = (users*movies).sum(dim=1)\n",
        "        res += self.user_bias[index_user_list] + self.movie_bias[index_movie_list]\n",
        "\n",
        "        return torch.special.expit(res) * 5.5"
      ],
      "metadata": {
        "id": "MWykadlbg3TJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_users = ratings.userId.nunique()\n",
        "n_movies = ratings.movieId.nunique()\n",
        "\n",
        "user_dict = pd.unique(ratings.userId)\n",
        "movie_dict = pd.unique(ratings.movieId)"
      ],
      "metadata": {
        "id": "InpeZ1T6k5m6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DotProductBias(n_users, n_movies, 10,movie_code = movie_dict,user_code = user_dict)"
      ],
      "metadata": {
        "id": "E1C3uXoGkkNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "  print(type(param), param.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iwmy4ZxW6no",
        "outputId": "ed578ddf-32f5-469e-d979-b3e13af52325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.nn.parameter.Parameter'> torch.Size([406, 10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([406])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([6489, 10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([6489])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "6KrFPEAykxoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "HIibZBF0mYC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = float(len(dataloader.dataset))\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "\n",
        "\n",
        "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "RIab5cuFnPXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_d, model, loss_fn, optimizer)\n",
        "    test(test_d, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jiuj1HoUpEKK",
        "outputId": "27b859d5-4990-43d6-cb39-0f35a31b259a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 494.909381  [  256/40000]\n",
            "loss: 448.698235  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 385.005409 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 424.383682  [  256/40000]\n",
            "loss: 333.649951  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 304.979796 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 325.750266  [  256/40000]\n",
            "loss: 234.945362  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 245.934938 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 240.672258  [  256/40000]\n",
            "loss: 188.456969  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 222.865779 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 201.677911  [  256/40000]\n",
            "loss: 183.653652  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 213.117817 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 183.137046  [  256/40000]\n",
            "loss: 127.731001  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 207.639847 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 166.826911  [  256/40000]\n",
            "loss: 145.952593  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 204.284928 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 179.993366  [  256/40000]\n",
            "loss: 185.557210  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 201.890839 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 148.951690  [  256/40000]\n",
            "loss: 157.657856  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 200.422490 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 150.652374  [  256/40000]\n",
            "loss: 130.959538  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 199.222111 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 145.745394  [  256/40000]\n",
            "loss: 145.503498  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 198.665781 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 142.647127  [  256/40000]\n",
            "loss: 115.384112  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 198.256473 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 121.045742  [  256/40000]\n",
            "loss: 132.543007  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 198.116035 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 141.090168  [  256/40000]\n",
            "loss: 115.720321  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 198.091741 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 96.065336  [  256/40000]\n",
            "loss: 112.268254  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 198.228769 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 131.301733  [  256/40000]\n",
            "loss: 101.516365  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 198.570151 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 96.209649  [  256/40000]\n",
            "loss: 115.546647  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 199.008295 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 126.884131  [  256/40000]\n",
            "loss: 99.208770  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 199.523534 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 80.891624  [  256/40000]\n",
            "loss: 112.842823  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 200.224115 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 106.561636  [  256/40000]\n",
            "loss: 123.735128  [25856/40000]\n",
            "Test Error: \n",
            " Avg loss: 200.869428 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = ratings.head(40).drop(axis = 1 , labels ='rating')\n",
        "tt = CustomTabularDataset(data)\n",
        "predicts = pd.Series([float(a) for a in model(tt)])"
      ],
      "metadata": {
        "id": "XUSecwWpJrqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show = ratings.head(40)\n",
        "show['predict'] = predicts\n",
        "show"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "94xvRyq-ONF5",
        "outputId": "6735a81b-c5e4-4261-d53c-3935d9f7b6c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-ae3b027ef06e>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  show['predict'] = predicts\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    userId  movieId  rating   predict\n",
              "0        1      296     5.0  4.575167\n",
              "1        1      306     3.5  4.661409\n",
              "2        1      307     5.0  4.763078\n",
              "3        1      665     5.0  4.282281\n",
              "4        1      899     3.5  4.056901\n",
              "5        1     1088     4.0  3.577064\n",
              "6        1     1175     3.5  4.324460\n",
              "7        1     1217     3.5  3.940863\n",
              "8        1     1237     5.0  4.520153\n",
              "9        1     1250     4.0  4.124517\n",
              "10       1     1260     3.5  4.131857\n",
              "11       1     1653     4.0  4.083290\n",
              "12       1     2011     2.5  3.778949\n",
              "13       1     2012     2.5  3.761797\n",
              "14       1     2068     2.5  2.514777\n",
              "15       1     2161     3.5  3.256074\n",
              "16       1     2351     4.5  4.386659\n",
              "17       1     2573     4.0  3.273439\n",
              "18       1     2632     5.0  4.437030\n",
              "19       1     2692     5.0  4.471656\n",
              "20       1     2843     4.5  4.533687\n",
              "21       1     3448     4.0  4.234084\n",
              "22       1     3569     5.0  4.435679\n",
              "23       1     3949     5.0  4.038880\n",
              "24       1     4144     5.0  4.274631\n",
              "25       1     4308     3.0  3.987715\n",
              "26       1     4325     5.0  2.985748\n",
              "27       1     4422     3.0  3.395465\n",
              "28       1     4703     4.0  4.256899\n",
              "29       1     4973     4.5  4.568598\n",
              "30       1     5147     4.0  3.945568\n",
              "31       1     5269     0.5  1.878533\n",
              "32       1     5684     2.0  1.961049\n",
              "33       1     5767     5.0  4.443017\n",
              "34       1     5878     4.0  4.358824\n",
              "35       1     5912     3.0  2.972367\n",
              "36       1     5952     4.0  4.255297\n",
              "37       1     6016     5.0  4.882484\n",
              "38       1     6370     4.5  4.071115\n",
              "39       1     6377     4.0  4.039669"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e83e458b-0fbd-4c65-821c-17665ac34837\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.575167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>306</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.661409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>307</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.763078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>665</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.282281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>899</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.056901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1088</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.577064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1175</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.324460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1217</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.940863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1237</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.520153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1250</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.124517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>1260</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.131857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>1653</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.083290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.778949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>2012</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.761797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>2068</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.514777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>2161</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.256074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>2351</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.386659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>2573</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.273439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>2632</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.437030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>2692</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.471656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>2843</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.533687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>3448</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.234084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "      <td>3569</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.435679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "      <td>3949</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.038880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>4144</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.274631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "      <td>4308</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.987715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "      <td>4325</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.985748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>4422</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.395465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1</td>\n",
              "      <td>4703</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.256899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "      <td>4973</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.568598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1</td>\n",
              "      <td>5147</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.945568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1</td>\n",
              "      <td>5269</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.878533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1</td>\n",
              "      <td>5684</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.961049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1</td>\n",
              "      <td>5767</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.443017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>1</td>\n",
              "      <td>5878</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.358824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>1</td>\n",
              "      <td>5912</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.972367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1</td>\n",
              "      <td>5952</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.255297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1</td>\n",
              "      <td>6016</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.882484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>1</td>\n",
              "      <td>6370</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.071115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>1</td>\n",
              "      <td>6377</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.039669</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e83e458b-0fbd-4c65-821c-17665ac34837')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e83e458b-0fbd-4c65-821c-17665ac34837 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e83e458b-0fbd-4c65-821c-17665ac34837');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0820aa9f-280b-4e49-82be-05f363008d3f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0820aa9f-280b-4e49-82be-05f363008d3f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0820aa9f-280b-4e49-82be-05f363008d3f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rcQ1TyridyBv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}